{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hotel reservations cancellations prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standard library imports\n",
                "import os\n",
                "import zipfile\n",
                "\n",
                "# Numerical and data manipulation libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "# Plotting and visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Machine learning libraries\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction import DictVectorizer\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# Metrics for model evaluation\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
                ")\n",
                "\n",
                "# Imbalanced data handling\n",
                "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
                "\n",
                "import pickle\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('hotel_reservations.csv')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<!-- README_INCLUDE -->\n",
                "The database used for the model consists in a set of bookings from a hotel with a unique id called ¨boooking_id¨ from 2017 and 2018."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Preparation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Convert all column values into lower case and replace spaces"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
                "\n",
                "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
                "\n",
                "for c in categorical_columns:\n",
                "    df[c] = df[c].str.lower().str.replace(' ', '_')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "total_people\n",
                            "2     23942\n",
                            "1      7552\n",
                            "3      3851\n",
                            "4       912\n",
                            "5        15\n",
                            "12        1\n",
                            "10        1\n",
                            "11        1\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df['total_people']  = df['no_of_adults'] + df['no_of_children']\n",
                "df['total_people'] .value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['price_per_adult'] = df['avg_price_per_room'] // df['no_of_adults']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['price_per_person']  = df['avg_price_per_room'] // df['total_people']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['has_prev_cancellations'] = df['no_of_previous_cancellations'] > 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['has_prev_bookings_not_cancelled'] = df['no_of_previous_bookings_not_canceled'] > 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['total_nights'] = df['no_of_weekend_nights'] + df['no_of_week_nights']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['have_children'] = df['no_of_children'] > 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "have_children\n",
                            "0    33577\n",
                            "1     2698\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df['have_children'] = df['have_children'].astype('int')\n",
                "df['have_children'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "def is_leap_year(year):\n",
                "    return (year % 4 == 0 and (year % 100 != 0 or year % 400 == 0))\n",
                "\n",
                "def adjust_for_feb_29(year, month, day):\n",
                "    if month == 2 and day == 29 and not is_leap_year(year):\n",
                "        return (month, 28)  \n",
                "    return (month, day)\n",
                "\n",
                "df['arrival_month'] = df['arrival_month'].apply(lambda x: f'{int(x):02d}')\n",
                "df['arrival_date'] = df['arrival_date'].apply(lambda x: f'{int(x):02d}')\n",
                "\n",
                "df[['arrival_month', 'arrival_date']] = df.apply(\n",
                "    lambda row: adjust_for_feb_29(row['arrival_year'], row['arrival_month'], row['arrival_date']), axis=1,\n",
                "    result_type='expand'\n",
                ")\n",
                "\n",
                "df['arrival_date_complete'] = pd.to_datetime(\n",
                "    df[['arrival_year', 'arrival_month', 'arrival_date']].astype(str).agg('-'.join, axis=1),\n",
                "    format='%Y-%m-%d', errors='coerce'\n",
                ")\n",
                "\n",
                "\n",
                "df['arrival_date_complete'] = df['arrival_date_complete'].fillna(pd.to_datetime('2018-02-28'))\n",
                "\n",
                "df['arrival_date_complete'] = pd.to_datetime(df['arrival_date_complete'])\n",
                "\n",
                "df['wday'] = df['arrival_date_complete'].dt.day_name()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature selection and model preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/pz/bvpq88x94b1c7g8rq2gf4j3r0000gn/T/ipykernel_48654/2779291360.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
                        "  df['booking_cancelled_flag'] = df['booking_status'].replace({'canceled': 1, 'not_canceled': 0})\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "Index(['no_of_adults', 'no_of_weekend_nights', 'no_of_week_nights',\n",
                            "       'type_of_meal_plan', 'required_car_parking_space', 'room_type_reserved',\n",
                            "       'lead_time', 'arrival_month', 'market_segment_type', 'repeated_guest',\n",
                            "       'avg_price_per_room', 'no_of_special_requests', 'price_per_person',\n",
                            "       'total_nights', 'have_children', 'arrival_date_complete', 'wday',\n",
                            "       'booking_cancelled_flag'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# from df dropping 'booking_id','no_of_previous_cancellations','arrival_year','arrival_date','no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled','has_prev_cancellations', 'has_prev_bookings_not_cancelled','segment_days_week','arrival_date_complete', 'month_year', 'no_of_children', 'no_of_adults','price_per_adult', 'price_per_person'\n",
                "df = df.drop(['booking_id','no_of_previous_cancellations','arrival_date','no_of_previous_cancellations', 'arrival_year',\n",
                "              'no_of_previous_bookings_not_canceled','has_prev_cancellations', 'has_prev_bookings_not_cancelled',\n",
                "               'price_per_adult','no_of_children' ,'total_people'], axis=1)\n",
                "\n",
                "# change booking_status to 0 and 1\n",
                "df['booking_cancelled_flag'] = df['booking_status'].replace({'canceled': 1, 'not_canceled': 0})\n",
                "\n",
                "# drop booking_status\n",
                "df = df.drop(['booking_status'], axis=1)\n",
                "\n",
                "df.columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "have children change from bool to 1-0\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "arrival_month\n",
                            "10    5317\n",
                            "9     4611\n",
                            "8     3813\n",
                            "6     3203\n",
                            "12    3021\n",
                            "11    2980\n",
                            "7     2920\n",
                            "4     2736\n",
                            "5     2598\n",
                            "3     2358\n",
                            "2     1704\n",
                            "1     1014\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# from arrival month in date to number\n",
                "df['arrival_month'] = df['arrival_month'].astype('int')\n",
                "df['arrival_month'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train test split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical= ['type_of_meal_plan', 'room_type_reserved', 'market_segment_type', 'wday']\n",
                "numerical = ['no_of_weekend_nights', 'no_of_week_nights', 'required_car_parking_space', 'lead_time', 'repeated_guest',  'price_per_person',\n",
                "        'avg_price_per_room', 'no_of_special_requests','total_nights', 'arrival_month', \n",
                "              'no_of_adults', 'have_children']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "29020 7255\n",
                        "21765 7255 7255\n"
                    ]
                }
            ],
            "source": [
                "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1, stratify=df['booking_cancelled_flag'])\n",
                "print(len(df_full_train), len(df_test))\n",
                "\n",
                "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1, stratify=df_full_train['booking_cancelled_flag'])\n",
                "print(len(df_train), len(df_val), len(df_test))\n",
                "\n",
                "df_train = df_train.reset_index(drop=True)\n",
                "df_val = df_val.reset_index(drop=True)\n",
                "df_test = df_test.reset_index(drop=True)\n",
                "df_full_train = df_full_train.reset_index(drop=True)\n",
                "\n",
                "y_train = df_train.booking_cancelled_flag.values\n",
                "y_val = df_val.booking_cancelled_flag.values\n",
                "y_test = df_test.booking_cancelled_flag.values\n",
                "y_full_train = df_full_train.booking_cancelled_flag.values\n",
                "\n",
                "del df_train['booking_cancelled_flag']\n",
                "del df_val['booking_cancelled_flag']\n",
                "del df_test['booking_cancelled_flag']\n",
                "del df_full_train['booking_cancelled_flag']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training the final model with SMOTE...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/envs/ml-zoomcamp39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
                        "  warnings.warn(\n",
                        "/opt/anaconda3/envs/ml-zoomcamp39/lib/python3.9/site-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[0]\ttrain-logloss:0.62734\n",
                        "[5]\ttrain-logloss:0.42616\n",
                        "[10]\ttrain-logloss:0.32635\n",
                        "[15]\ttrain-logloss:0.26848\n",
                        "[20]\ttrain-logloss:0.23389\n",
                        "[25]\ttrain-logloss:0.21203\n",
                        "[30]\ttrain-logloss:0.19692\n",
                        "[35]\ttrain-logloss:0.18708\n",
                        "[40]\ttrain-logloss:0.17930\n",
                        "[45]\ttrain-logloss:0.17189\n",
                        "[50]\ttrain-logloss:0.16521\n",
                        "[55]\ttrain-logloss:0.15994\n",
                        "[60]\ttrain-logloss:0.15572\n",
                        "[65]\ttrain-logloss:0.15128\n",
                        "[70]\ttrain-logloss:0.14753\n",
                        "[75]\ttrain-logloss:0.14397\n",
                        "[80]\ttrain-logloss:0.13919\n",
                        "[85]\ttrain-logloss:0.13655\n",
                        "[90]\ttrain-logloss:0.13294\n",
                        "[95]\ttrain-logloss:0.13014\n",
                        "[100]\ttrain-logloss:0.12716\n",
                        "[105]\ttrain-logloss:0.12375\n",
                        "[110]\ttrain-logloss:0.12012\n",
                        "[115]\ttrain-logloss:0.11846\n",
                        "[120]\ttrain-logloss:0.11514\n",
                        "[125]\ttrain-logloss:0.11209\n",
                        "[130]\ttrain-logloss:0.10959\n",
                        "[135]\ttrain-logloss:0.10851\n",
                        "[140]\ttrain-logloss:0.10455\n",
                        "[145]\ttrain-logloss:0.10203\n",
                        "[150]\ttrain-logloss:0.10028\n",
                        "[155]\ttrain-logloss:0.09845\n",
                        "[160]\ttrain-logloss:0.09553\n",
                        "[165]\ttrain-logloss:0.09260\n",
                        "[170]\ttrain-logloss:0.09041\n",
                        "[175]\ttrain-logloss:0.08846\n",
                        "[180]\ttrain-logloss:0.08688\n",
                        "[185]\ttrain-logloss:0.08480\n",
                        "[190]\ttrain-logloss:0.08306\n",
                        "[195]\ttrain-logloss:0.08175\n",
                        "[199]\ttrain-logloss:0.08085\n",
                        "Validation Accuracy: 97.09%\n",
                        "Validation Precision: 96.01%\n",
                        "Validation Recall: 95.08%\n",
                        "Validation F1 Score: 95.54%\n",
                        "Validation ROC AUC Score: 99.70%\n",
                        "Training the final model on the full dataset with SMOTE...\n",
                        "[0]\ttrain-logloss:0.62734\n",
                        "[5]\ttrain-logloss:0.42616\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/envs/ml-zoomcamp39/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
                        "  warnings.warn(\n",
                        "/opt/anaconda3/envs/ml-zoomcamp39/lib/python3.9/site-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[10]\ttrain-logloss:0.32635\n",
                        "[15]\ttrain-logloss:0.26848\n",
                        "[20]\ttrain-logloss:0.23389\n",
                        "[25]\ttrain-logloss:0.21203\n",
                        "[30]\ttrain-logloss:0.19692\n",
                        "[35]\ttrain-logloss:0.18708\n",
                        "[40]\ttrain-logloss:0.17930\n",
                        "[45]\ttrain-logloss:0.17189\n",
                        "[50]\ttrain-logloss:0.16521\n",
                        "[55]\ttrain-logloss:0.15994\n",
                        "[60]\ttrain-logloss:0.15572\n",
                        "[65]\ttrain-logloss:0.15128\n",
                        "[70]\ttrain-logloss:0.14753\n",
                        "[75]\ttrain-logloss:0.14397\n",
                        "[80]\ttrain-logloss:0.13919\n",
                        "[85]\ttrain-logloss:0.13655\n",
                        "[90]\ttrain-logloss:0.13294\n",
                        "[95]\ttrain-logloss:0.13014\n",
                        "[100]\ttrain-logloss:0.12716\n",
                        "[105]\ttrain-logloss:0.12375\n",
                        "[110]\ttrain-logloss:0.12012\n",
                        "[115]\ttrain-logloss:0.11846\n",
                        "[120]\ttrain-logloss:0.11514\n",
                        "[125]\ttrain-logloss:0.11209\n",
                        "[130]\ttrain-logloss:0.10959\n",
                        "[135]\ttrain-logloss:0.10851\n",
                        "[140]\ttrain-logloss:0.10455\n",
                        "[145]\ttrain-logloss:0.10203\n",
                        "[150]\ttrain-logloss:0.10028\n",
                        "[155]\ttrain-logloss:0.09845\n",
                        "[160]\ttrain-logloss:0.09553\n",
                        "[165]\ttrain-logloss:0.09260\n",
                        "[170]\ttrain-logloss:0.09041\n",
                        "[175]\ttrain-logloss:0.08846\n",
                        "[180]\ttrain-logloss:0.08688\n",
                        "[185]\ttrain-logloss:0.08480\n",
                        "[190]\ttrain-logloss:0.08306\n",
                        "[195]\ttrain-logloss:0.08175\n",
                        "[199]\ttrain-logloss:0.08085\n",
                        "Test Accuracy: 89.81%\n",
                        "Test Precision: 86.34%\n",
                        "Test Recall: 81.87%\n",
                        "Test F1 Score: 84.04%\n",
                        "Test ROC AUC Score: 95.58%\n",
                        "The model and DictVectorizer are saved to xgboost_model_booking_cancellation_smote.bin\n"
                    ]
                }
            ],
            "source": [
                "from imblearn.over_sampling import SMOTE\n",
                "import pickle\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
                "\n",
                "# Training function with SMOTE integration\n",
                "def train_with_smote(df_train, y_train, params, categorical, numerical):\n",
                "    # Convert to dictionary and transform using DictVectorizer\n",
                "    train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
                "    dv = DictVectorizer(sparse=False)\n",
                "    X_train = dv.fit_transform(train_dict)\n",
                "    \n",
                "    # Apply SMOTE to balance the dataset\n",
                "    smote = SMOTE(random_state=42, sampling_strategy=1)\n",
                "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
                "    \n",
                "    # Create a DMatrix for training\n",
                "    features = list(dv.get_feature_names_out())\n",
                "    dtrain = xgb.DMatrix(X_resampled, label=y_resampled, feature_names=features)\n",
                "    \n",
                "    # Train the model\n",
                "    model = xgb.train(\n",
                "        params, \n",
                "        dtrain, \n",
                "        num_boost_round=200, \n",
                "        evals=[(dtrain, 'train')], \n",
                "        verbose_eval=5, \n",
                "        early_stopping_rounds=5\n",
                "    )\n",
                "    \n",
                "    return dv, model\n",
                "\n",
                "# Prediction function\n",
                "def predict(df, dv, model, categorical, numerical):\n",
                "    # Transform input data using DictVectorizer\n",
                "    data_dict = df[categorical + numerical].to_dict(orient='records')\n",
                "    X = dv.transform(data_dict)\n",
                "    features = list(dv.get_feature_names_out())  # Ensure it's a list\n",
                "    dmatrix = xgb.DMatrix(X, feature_names=features)\n",
                "    \n",
                "    # Predict probabilities\n",
                "    y_pred = model.predict(dmatrix)\n",
                "    return y_pred\n",
                "\n",
                "# XGBoost parameters\n",
                "xgb_params = {\n",
                "    'eta': 0.1,\n",
                "    'max_depth': 12,\n",
                "    'min_child_weight': 1,\n",
                "    'objective': 'binary:logistic',\n",
                "    'nthread': 8,\n",
                "    'seed': 1,\n",
                "    'verbosity': 1\n",
                "}\n",
                "\n",
                "\n",
                "# Training the model with SMOTE\n",
                "print('Training the final model with SMOTE...')\n",
                "dv, model = train_with_smote(df_full_train, y_full_train, xgb_params, categorical, numerical)\n",
                "\n",
                "# Validate the model\n",
                "y_pred_val = predict(df_val, dv, model, categorical, numerical)\n",
                "y_pred_binary_val = (y_pred_val >= 0.5).astype(int)\n",
                "\n",
                "# Final training on the full training set with SMOTE\n",
                "print('Training the final model on the full dataset with SMOTE...')\n",
                "dv, model = train_with_smote(df_full_train, y_full_train, xgb_params, categorical, numerical)\n",
                "\n",
                "# Test set evaluation\n",
                "y_pred_test = predict(df_test, dv, model, categorical, numerical)\n",
                "y_pred_binary_test = (y_pred_test >= 0.5).astype(int)\n",
                "\n",
                "# Evaluate test performance\n",
                "accuracy_test = accuracy_score(y_test, y_pred_binary_test)\n",
                "precision_test = precision_score(y_test, y_pred_binary_test)\n",
                "recall_test = recall_score(y_test, y_pred_binary_test)\n",
                "f1_test = f1_score(y_test, y_pred_binary_test)\n",
                "roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
                "\n",
                "print(f'Test Accuracy: {accuracy_test * 100:.2f}%')\n",
                "print(f'Test Precision: {precision_test * 100:.2f}%')\n",
                "print(f'Test Recall: {recall_test * 100:.2f}%')\n",
                "print(f'Test F1 Score: {f1_test * 100:.2f}%')\n",
                "print(f'Test ROC AUC Score: {roc_auc_test * 100:.2f}%')\n",
                "\n",
                "# Save the final model and DictVectorizer\n",
                "output_file = 'xgboost_model_booking_cancellation_smote.bin'\n",
                "with open(output_file, 'wb') as f_out:\n",
                "    pickle.dump((dv, model), f_out)\n",
                "\n",
                "print(f'The model and DictVectorizer are saved to {output_file}')\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ml-zoomcamp39",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
